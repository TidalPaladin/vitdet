fit:
  trainer:
    accelerator: gpu
    devices: 2
    strategy: "ddp_find_unused_parameters_true"
    precision: "bf16-mixed"
    max_steps: 500000
    num_sanity_val_steps: 2
    default_root_dir: /mnt/iscsi/outputs/vitdet
    gradient_clip_val: 5.0
    gradient_clip_algorithm: "norm"
    callbacks:
      - class_path: pytorch_lightning.callbacks.ModelCheckpoint
        init_args:
          filename: "epoch={epoch}-step={step}-loss={val/loss:.4f}"
          monitor: "val/loss"
          auto_insert_metric_name: false
          mode: min
          save_last: true

    logger:
      class_path: pytorch_lightning.loggers.wandb.WandbLogger
      init_args:
        save_dir: /mnt/iscsi/outputs/vitdet

  model:
    class_path: deep_helpers.tasks.MultiTask
    init_args:
      tasks:
        -
          - "contrastive"
          - class_path: vitdet.train.contrastive.ContrastiveEmbedding
            init_args:
              backbone: "vitdet_base_patch8_224"
        -
          - "mae"
          - class_path: vitdet.train.mae.MAE
            init_args:
              backbone: "vitdet_base_patch8_224"
      optimizer_init:
        class_path: torch.optim.AdamW
        init_args:
          lr: 0.00005
          weight_decay: 0.05
      weight_decay_exemptions:
        - "bias"
        - "LayerNorm"
      lr_interval: "step"
      lr_scheduler_init:
        class_path: torch.optim.lr_scheduler.OneCycleLR
        init_args:
          max_lr: 0.00005
          div_factor: 5
          final_div_factor: 50
          pct_start: 0.1
          three_phase: false
          total_steps: 500000

  data:
    class_path: vitdet.train.imagenet.ImagenetDataModule
    init_args:
      data_dir: /mnt/datasets/vision/imagenet/ILSVRC/Data/CLS-LOC
      batch_size: 32
      num_workers: 12
